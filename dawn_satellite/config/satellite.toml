# DAWN Satellite Configuration
#
# This file configures a DAP2 (Tier 1) satellite device.
# Deploy the same hardware config to all identical satellites,
# then customize [identity] per device.

# =============================================================================
# General Settings
# =============================================================================
[general]
# AI name - must match server dawn.toml
ai_name = "friday"

# =============================================================================
# Identity - UNIQUE PER SATELLITE
# =============================================================================
[identity]
# Unique identifier (auto-generated if empty)
# Use: uuidgen | tr '[:upper:]' '[:lower:]'
uuid = ""

# Human-readable name shown in daemon logs and WebUI
name = "Satellite"

# Room/location for context-aware responses
# e.g., "kitchen", "bedroom", "living_room", "office"
location = ""

# =============================================================================
# Server Connection
# =============================================================================
[server]
# DAWN daemon hostname or IP address
host = "localhost"

# WebUI port (where WebSocket server runs)
port = 3000

# Use secure WebSocket (wss://) - requires SSL cert on daemon
ssl = true

# Verify SSL certificates (default: true)
# Set to false ONLY for development with self-signed certificates
# WARNING: Disabling this in production enables man-in-the-middle attacks!
ssl_verify = true

# Path to CA certificate for SSL verification
# Set this to the DAWN private CA cert (ca.crt) from generate_ssl_cert.sh
# Empty string = use system CA bundle
ca_cert_path = ""

# Reconnect settings
reconnect_delay_ms = 5000
max_reconnect_attempts = 0  # 0 = infinite

# =============================================================================
# Audio Configuration
# =============================================================================
[audio]
# ALSA device names - use 'arecord -l' and 'aplay -l' to list devices
#
# Common devices:
#   "plughw:0,0"     - Default sound card
#   "plughw:1,0"     - USB sound card (typical for ReSpeaker)
#   "plughw:2,0"     - Second USB device
#   "default"        - PulseAudio default (if running)

capture_device = "plughw:0,0"
playback_device = "plughw:0,0"

# Sample rate (must match daemon expectations)
sample_rate = 16000

# Maximum recording time in seconds (safety limit)
max_record_seconds = 30

# =============================================================================
# Hardware - GPIO Button (optional, for Tier 2 or development)
# =============================================================================
[gpio]
# Tier 1 uses VAD + wake word, not push-to-talk
# Enable only for development/testing or Tier 2 devices
enabled = false

# GPIO chip (usually "gpiochip0" on RPi)
chip = "gpiochip0"

# Button GPIO pin number (BCM numbering)
button_pin = 17
button_active_low = true

# Discrete RGB LED pins (BCM numbering, -1 = disabled)
# For custom builds with individual R/G/B indicator LEDs
led_red_pin = -1
led_green_pin = -1
led_blue_pin = -1

# =============================================================================
# Hardware - NeoPixel/WS2812 LEDs (optional, for Tier 2 or custom builds)
# =============================================================================
[neopixel]
# Tier 1 RPi satellites typically don't use indicator LEDs
# Enable for custom builds with LED feedback
enabled = false

spi_device = "/dev/spidev0.0"
num_leds = 3
brightness = 64

# =============================================================================
# Hardware - SPI Display (optional)
# =============================================================================
[display]
# Enable SPI display (ST7735, ILI9341, etc.)
enabled = false

# Framebuffer device
device = "/dev/fb1"

# =============================================================================
# SDL2 Touchscreen UI (optional, for Pi with 7" display)
# =============================================================================
[sdl_ui]
# Enable SDL2 orb visualization + transcript panel
# Requires: libsdl2-dev libsdl2-ttf-dev, build with -DENABLE_SDL_UI=ON
enabled = false

# Display resolution (default: 1024x600 for 7" touchscreen)
width = 1024
height = 600

# Path to TTF font files (default: assets/fonts/)
# Requires: IBMPlexMono-Regular.ttf, SourceSans3-Regular.ttf
font_dir = "assets/fonts"

# Saved slider values (10-100 brightness, 0-100 volume)
# Automatically updated when sliders are adjusted via the UI
brightness = 100
volume = 80
time_24h = false
theme = "cyan"

# =============================================================================
# Screensaver / Ambient Mode
# =============================================================================
[screensaver]
# Enable screensaver after idle timeout (no touch or voice activity)
# Clock mode when no music, rainbow visualizer when music is playing
enabled = true

# Idle timeout in seconds before screensaver activates (30-600)
timeout = 120

# =============================================================================
# Voice Activity Detection (VAD)
# =============================================================================
[vad]
# VAD is used to detect end-of-speech after wake word
# Model: Silero VAD (same as main daemon)
enabled = true

# Path to Silero VAD ONNX model
model_path = "models/silero_vad_16k_op15.onnx"

# Silence duration (ms) to trigger end-of-speech
silence_duration_ms = 800

# Minimum speech duration (ms) before accepting
min_speech_ms = 250

# VAD threshold (0.0-1.0, higher = more strict)
threshold = 0.5

# =============================================================================
# Wake Word Detection
# =============================================================================
[wake_word]
# Enable always-on wake word detection
enabled = true

# Wake word (matches main daemon)
word = "friday"

# Sensitivity (0.0-1.0, higher = more sensitive but more false positives)
sensitivity = 0.5

# =============================================================================
# Automatic Speech Recognition (ASR)
# =============================================================================
[asr]
# ASR engine: "whisper" (batch, higher accuracy) or "vosk" (streaming, near-instant)
# Whisper: accumulates audio, runs inference at end (~4s on Pi 4 for tiny model)
# Vosk: processes audio incrementally, finalize() returns near-instantly
engine = "vosk"

# Model path depends on engine:
#   Whisper: path to .bin model file
#     Recommended: ggml-tiny.en-q5_1.bin (~30MB, fastest for Pi 4)
#     Alternative: ggml-tiny.en.bin (~77MB), ggml-tiny.bin (~75MB, multilingual)
#   Vosk: path to model directory
#     Recommended: vosk-model-small-en-us-0.15 (~40MB)
#     Alternative: vosk-model-en-us-0.22 (~1.8GB, better accuracy)
model_path = "models/vosk-model-small-en-us-0.15"

# Language code (en, es, fr, de, etc.)
language = "en"

# Number of processing threads (Pi 4 has 4 cores)
n_threads = 4

# Maximum recording duration in seconds
# Lower = less memory. 15s uses 960KB buffer (not 3.84MB at 60s)
max_audio_seconds = 15

# =============================================================================
# Text-to-Speech (TTS)
# =============================================================================
[tts]
# Piper voice model
model_path = "models/en_GB-alba-medium.onnx"
config_path = "models/en_GB-alba-medium.onnx.json"

# espeak-ng data path for phonemization
espeak_data = "/usr/share/espeak-ng-data"

# Speech speed (1.0 = normal, 0.85 = faster)
length_scale = 0.85

# =============================================================================
# Processing Mode
# =============================================================================
[processing]
# Processing mode:
#   "text_only"       - Current: keyboard input, useful for testing
#   "voice_activated" - Production: VAD + wake word + ASR + TTS
mode = "voice_activated"

# =============================================================================
# Logging
# =============================================================================
[logging]
# Log level: "error", "warning", "info", "debug"
level = "info"

# Log to syslog instead of stdout
use_syslog = false
