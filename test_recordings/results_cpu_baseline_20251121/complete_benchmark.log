================================================================================
DAWN Complete ASR Benchmark
Date: Mon Nov 17 10:11:04 PM UTC 2025
Files: 50
================================================================================

LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:19:58.885 asr_benchmark.c:102:     Loaded WAV: test_031.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:19:58.885 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:20:14.312 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:20:14.312 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:20:17.743 asr_vosk.c:247:          Vosk: Final result: "friday turn on the lights in the bedroom and kitchen" (confidence: -1.00)[0m
[32m[INFO] 22:20:17.743 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:20:17.976 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:20:18.134 asr_benchmark.c:102:     Loaded WAV: test_032.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:20:18.134 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:20:32.917 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:20:32.918 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:20:36.561 asr_vosk.c:247:          Vosk: Final result: "friday can you give me an update on the system status" (confidence: -1.00)[0m
[32m[INFO] 22:20:36.562 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:20:36.795 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:20:36.928 asr_benchmark.c:102:     Loaded WAV: test_033.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:20:36.928 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:20:51.530 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:20:51.530 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:20:54.928 asr_vosk.c:247:          Vosk: Final result: "friday i'm going to do a little bit of testing" (confidence: -1.00)[0m
[32m[INFO] 22:20:54.928 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:20:55.158 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:20:55.325 asr_benchmark.c:102:     Loaded WAV: test_034.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:20:55.325 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:21:10.080 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:21:10.080 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:21:13.538 asr_vosk.c:247:          Vosk: Final result: "friday remind me to check the server logs later" (confidence: -1.00)[0m
[32m[INFO] 22:21:13.538 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:21:13.769 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:21:13.930 asr_benchmark.c:102:     Loaded WAV: test_035.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:21:13.931 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:21:28.783 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:21:28.784 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:21:32.221 asr_vosk.c:247:          Vosk: Final result: "friday what were the results of the last benchmark" (confidence: -1.00)[0m
[32m[INFO] 22:21:32.221 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:21:32.452 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:21:32.618 asr_benchmark.c:102:     Loaded WAV: test_036.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:21:32.618 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:21:47.335 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:21:47.335 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:21:51.191 asr_vosk.c:247:          Vosk: Final result: "friday can you explain how the s r system works" (confidence: -1.00)[0m
[32m[INFO] 22:21:51.191 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:21:51.423 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:21:51.556 asr_benchmark.c:102:     Loaded WAV: test_037.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:21:51.556 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:22:06.388 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:22:06.388 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:22:09.993 asr_vosk.c:247:          Vosk: Final result: "friday show me the current cpu and memory usage" (confidence: -1.00)[0m
[32m[INFO] 22:22:09.993 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:22:10.227 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:22:10.360 asr_benchmark.c:102:     Loaded WAV: test_038.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:22:10.360 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:22:24.986 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:22:24.986 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:22:28.394 asr_vosk.c:247:          Vosk: Final result: "friday i need help troubleshooting a network issue" (confidence: -1.00)[0m
[32m[INFO] 22:22:28.395 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:22:28.630 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:22:28.761 asr_benchmark.c:102:     Loaded WAV: test_039.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:22:28.762 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:22:43.494 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:22:43.494 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:22:47.123 asr_vosk.c:247:          Vosk: Final result: "friday what sensors are currently active in the house" (confidence: -1.00)[0m
[32m[INFO] 22:22:47.124 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:22:47.356 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:22:47.490 asr_benchmark.c:102:     Loaded WAV: test_040.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:22:47.491 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:23:02.148 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:23:02.148 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:23:05.530 asr_vosk.c:247:          Vosk: Final result: "friday give me a summary of today's activities" (confidence: -1.00)[0m
[32m[INFO] 22:23:05.530 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:23:05.762 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:23:05.896 asr_benchmark.c:102:     Loaded WAV: test_041.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:23:05.897 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:23:20.431 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:23:20.431 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:23:27.054 asr_vosk.c:247:          Vosk: Final result: "friday i'm going to do a little bit of testing just to see how my new text to speech as r is working and we're going to go ahead and run some benchmarks" (confidence: -1.00)[0m
[32m[INFO] 22:23:27.054 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:23:27.285 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:23:27.442 asr_benchmark.c:102:     Loaded WAV: test_042.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:23:27.442 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:23:41.982 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:23:41.982 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:23:48.110 asr_vosk.c:247:          Vosk: Final result: "friday can you tell me about the oasis project specs including mirage dawn aura and spark and what each component does" (confidence: -1.00)[0m
[32m[INFO] 22:23:48.110 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:23:48.343 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:23:48.486 asr_benchmark.c:102:     Loaded WAV: test_043.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:23:48.486 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:24:02.831 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:24:02.832 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:24:08.255 asr_vosk.c:247:          Vosk: Final result: "friday i need you to analyze the recent performance metrics and let me know if there are any anomalies or issues that need attention" (confidence: -1.00)[0m
[32m[INFO] 22:24:08.255 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:24:08.490 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:24:08.623 asr_benchmark.c:102:     Loaded WAV: test_044.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:24:08.623 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:24:23.008 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:24:23.009 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:24:28.401 asr_vosk.c:247:          Vosk: Final result: "friday could you please walk me through the steps to configure a new sensor and integrated with the existing home automation system" (confidence: -1.00)[0m
[32m[INFO] 22:24:28.402 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:24:28.637 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:24:28.769 asr_benchmark.c:102:     Loaded WAV: test_045.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:24:28.770 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:24:43.222 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:24:43.223 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:24:49.070 asr_vosk.c:247:          Vosk: Final result: "friday i'm experiencing some latency issues with the voice recognition and i'm wondering if it might be related to network bandwidth or processing power" (confidence: -1.00)[0m
[32m[INFO] 22:24:49.070 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:24:49.308 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:24:49.459 asr_benchmark.c:102:     Loaded WAV: test_046.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:24:49.459 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:25:04.053 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:25:04.054 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:25:09.523 asr_vosk.c:247:          Vosk: Final result: "friday give me a detailed breakdown of the energy consumption across all connected devices for the past week and highlight any unusual patterns" (confidence: -1.00)[0m
[32m[INFO] 22:25:09.523 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:25:09.762 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:25:09.907 asr_benchmark.c:102:     Loaded WAV: test_047.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:25:09.907 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:25:24.443 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:25:24.443 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:25:31.198 asr_vosk.c:247:          Vosk: Final result: "the friday i want to set up an automation routine that turns on the lights when i arrive home and adjust the thermostat based on the current weather" (confidence: -1.00)[0m
[32m[INFO] 22:25:31.198 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:25:31.433 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:25:31.576 asr_benchmark.c:102:     Loaded WAV: test_048.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:25:31.576 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:25:46.041 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:25:46.041 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:25:51.883 asr_vosk.c:247:          Vosk: Final result: "friday can you compare the performance of waske vs whisper for speech recognition accuracy real time factor and overall system resource usage" (confidence: -1.00)[0m
[32m[INFO] 22:25:51.883 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:25:52.116 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:25:52.252 asr_benchmark.c:102:     Loaded WAV: test_049.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:25:52.252 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:26:06.676 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:26:06.677 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:26:12.200 asr_vosk.c:247:          Vosk: Final result: "friday i need to know if the backup systems are functioning properly and when the last successful backup was completed for all critical data" (confidence: -1.00)[0m
[32m[INFO] 22:26:12.200 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:26:12.434 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:26:12.568 asr_benchmark.c:102:     Loaded WAV: test_050.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:26:12.568 asr_interface.c:63:      ASR: Initializing Vosk engine (model: ../model, sample_rate: 16000)[0m
LOG (VoskAPI:ReadDataFiles():model.cc:223) Decoding params beam=13 max-active=7000 lattice-beam=6
LOG (VoskAPI:ReadDataFiles():model.cc:226) Silence phones 1:2:3:4:5:11:12:13:14:15
LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.
LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.
LOG (VoskAPI:ReadDataFiles():model.cc:259) Loading i-vector extractor from ../model/ivector/final.ie
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor
LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.
LOG (VoskAPI:ReadDataFiles():model.cc:292) Loading HCLG from ../model/graph/HCLG.fst
LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading words from ../model/graph/words.txt
LOG (VoskAPI:ReadDataFiles():model.cc:321) Loading winfo ../model/graph/phones/word_boundary.int
LOG (VoskAPI:ReadDataFiles():model.cc:328) Loading subtract G.fst model from ../model/rescore/G.fst
LOG (VoskAPI:ReadDataFiles():model.cc:330) Loading CARPA model from ../model/rescore/G.carpa
LOG (VoskAPI:ReadDataFiles():model.cc:336) Loading RNNLM model from ../model/rnnlm/final.raw
[32m[INFO] 22:26:26.895 asr_vosk.c:151:          Vosk: Initialized successfully (model: ../model, sample_rate: 16000)[0m
[32m[INFO] 22:26:26.895 asr_interface.c:98:      ASR: Vosk engine initialized successfully[0m
[32m[INFO] 22:26:32.710 asr_vosk.c:247:          Vosk: Final result: "friday please explain the difference between streaming as r and batch processing and how that affects the responsiveness of the voice assistant" (confidence: -1.00)[0m
[32m[INFO] 22:26:32.710 asr_interface.c:148:     ASR: Cleaning up Vosk engine[0m
[32m[INFO] 22:26:32.946 asr_vosk.c:283:          Vosk: Cleanup complete[0m
[32m[INFO] 22:26:33.081 asr_benchmark.c:102:     Loaded WAV: test_001.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:33.082 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:33.286 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:33.286 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:34.526 asr_whisper.c:256:       Whisper: Final result: " Friday." (1240.1ms, RTF: 0.248)[0m
[32m[INFO] 22:26:34.526 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:34.552 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:34.657 asr_benchmark.c:102:     Loaded WAV: test_002.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:34.657 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:34.810 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:34.810 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:36.072 asr_whisper.c:256:       Whisper: Final result: " Okay Friday." (1261.8ms, RTF: 0.252)[0m
[32m[INFO] 22:26:36.072 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:36.098 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:36.202 asr_benchmark.c:102:     Loaded WAV: test_003.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:36.203 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:36.350 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:36.350 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:37.612 asr_whisper.c:256:       Whisper: Final result: " Hey Friday." (1261.5ms, RTF: 0.252)[0m
[32m[INFO] 22:26:37.612 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:37.637 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:37.761 asr_benchmark.c:102:     Loaded WAV: test_004.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:37.762 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:37.914 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:37.914 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:39.185 asr_whisper.c:256:       Whisper: Final result: " Friday are you there?" (1271.4ms, RTF: 0.254)[0m
[32m[INFO] 22:26:39.185 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:39.211 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:39.315 asr_benchmark.c:102:     Loaded WAV: test_005.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:39.316 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:39.460 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:39.460 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:40.653 asr_whisper.c:256:       Whisper: Final result: " Okay, Friday, are you listening?" (1193.2ms, RTF: 0.239)[0m
[32m[INFO] 22:26:40.654 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:40.679 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:40.784 asr_benchmark.c:102:     Loaded WAV: test_006.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:40.784 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:40.928 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:40.928 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:42.222 asr_whisper.c:256:       Whisper: Final result: " Friday." (1293.6ms, RTF: 0.259)[0m
[32m[INFO] 22:26:42.222 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:42.247 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:42.353 asr_benchmark.c:102:     Loaded WAV: test_007.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:42.353 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:42.498 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:42.498 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:43.657 asr_whisper.c:256:       Whisper: Final result: " Friday" (1158.7ms, RTF: 0.232)[0m
[32m[INFO] 22:26:43.657 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:43.683 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:43.788 asr_benchmark.c:102:     Loaded WAV: test_008.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:43.788 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:43.931 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:43.931 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:45.151 asr_whisper.c:256:       Whisper: Final result: " Friday, what time is it?" (1219.2ms, RTF: 0.244)[0m
[32m[INFO] 22:26:45.151 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:45.177 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:45.279 asr_benchmark.c:102:     Loaded WAV: test_009.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:45.279 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:45.424 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:45.424 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:46.599 asr_whisper.c:256:       Whisper: Final result: " Okay Friday, are you there?" (1175.3ms, RTF: 0.235)[0m
[32m[INFO] 22:26:46.599 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:46.625 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:46.731 asr_benchmark.c:102:     Loaded WAV: test_010.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:46.731 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:46.872 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:46.872 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:48.158 asr_whisper.c:256:       Whisper: Final result: " Friday." (1285.2ms, RTF: 0.257)[0m
[32m[INFO] 22:26:48.158 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:48.183 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:48.290 asr_benchmark.c:102:     Loaded WAV: test_011.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:48.290 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:48.432 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:48.432 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:49.604 asr_whisper.c:256:       Whisper: Final result: " Friday what time is it?" (1171.7ms, RTF: 0.234)[0m
[32m[INFO] 22:26:49.604 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:49.630 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:49.752 asr_benchmark.c:102:     Loaded WAV: test_012.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:49.752 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:49.893 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:49.893 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:51.067 asr_whisper.c:256:       Whisper: Final result: " Friday turn on the lights." (1174.1ms, RTF: 0.235)[0m
[32m[INFO] 22:26:51.067 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:51.092 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:51.208 asr_benchmark.c:102:     Loaded WAV: test_013.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:51.208 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:51.354 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:51.354 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:52.523 asr_whisper.c:256:       Whisper: Final result: " Friday turn off the lights." (1169.0ms, RTF: 0.234)[0m
[32m[INFO] 22:26:52.524 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:52.550 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:52.654 asr_benchmark.c:102:     Loaded WAV: test_014.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:52.654 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:52.796 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:52.796 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:54.007 asr_whisper.c:256:       Whisper: Final result: " Friday, what's the weather?" (1210.8ms, RTF: 0.242)[0m
[32m[INFO] 22:26:54.007 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:54.032 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:54.136 asr_benchmark.c:102:     Loaded WAV: test_015.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:54.136 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:54.279 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:54.279 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:55.455 asr_whisper.c:256:       Whisper: Final result: " For out a set of timer." (1175.9ms, RTF: 0.235)[0m
[32m[INFO] 22:26:55.455 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:55.481 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:55.587 asr_benchmark.c:102:     Loaded WAV: test_016.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:55.587 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:55.738 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:55.738 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:57.105 asr_whisper.c:256:       Whisper: Final result: " Friday, good morning." (1366.7ms, RTF: 0.273)[0m
[32m[INFO] 22:26:57.105 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:57.130 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:57.235 asr_benchmark.c:102:     Loaded WAV: test_017.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:57.235 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:57.373 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:57.373 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:26:58.637 asr_whisper.c:256:       Whisper: Final result: " Friday Good Night." (1264.3ms, RTF: 0.253)[0m
[32m[INFO] 22:26:58.637 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:26:58.663 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:26:58.770 asr_benchmark.c:102:     Loaded WAV: test_018.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:26:58.770 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:26:58.911 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:26:58.911 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:00.076 asr_whisper.c:256:       Whisper: Final result: " Friday, thank you." (1165.2ms, RTF: 0.233)[0m
[32m[INFO] 22:27:00.076 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:00.102 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:00.204 asr_benchmark.c:102:     Loaded WAV: test_019.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:00.204 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:00.343 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:00.344 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:01.528 asr_whisper.c:256:       Whisper: Final result: " Friday help me." (1184.7ms, RTF: 0.237)[0m
[32m[INFO] 22:27:01.529 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:01.554 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:01.658 asr_benchmark.c:102:     Loaded WAV: test_020.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:01.658 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:01.802 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:01.802 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:03.156 asr_whisper.c:256:       Whisper: Final result: " Friday stop." (1353.9ms, RTF: 0.271)[0m
[32m[INFO] 22:27:03.156 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:03.182 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:03.288 asr_benchmark.c:102:     Loaded WAV: test_021.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:03.288 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:03.435 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:03.435 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:04.781 asr_whisper.c:256:       Whisper: Final result: " Friday pause." (1345.9ms, RTF: 0.269)[0m
[32m[INFO] 22:27:04.781 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:04.807 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:04.911 asr_benchmark.c:102:     Loaded WAV: test_022.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:04.911 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:05.057 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:05.057 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:06.222 asr_whisper.c:256:       Whisper: Final result: " Friday, resume." (1165.1ms, RTF: 0.233)[0m
[32m[INFO] 22:27:06.222 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:06.248 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:06.353 asr_benchmark.c:102:     Loaded WAV: test_023.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:06.353 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:06.496 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:06.496 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:07.769 asr_whisper.c:256:       Whisper: Final result: " Friday, volume up." (1271.8ms, RTF: 0.254)[0m
[32m[INFO] 22:27:07.769 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:07.794 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:07.899 asr_benchmark.c:102:     Loaded WAV: test_024.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:07.899 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:08.044 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:08.044 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:09.254 asr_whisper.c:256:       Whisper: Final result: " Friday, volume down." (1209.9ms, RTF: 0.242)[0m
[32m[INFO] 22:27:09.254 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:09.280 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:09.384 asr_benchmark.c:102:     Loaded WAV: test_025.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:09.384 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:09.525 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:09.525 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:10.808 asr_whisper.c:256:       Whisper: Final result: " Friday, what can you do?" (1283.0ms, RTF: 0.257)[0m
[32m[INFO] 22:27:10.808 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:10.834 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:10.937 asr_benchmark.c:102:     Loaded WAV: test_026.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:10.937 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:11.080 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:11.080 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:12.335 asr_whisper.c:256:       Whisper: Final result: " Friday, can you tell me what the current time is please?" (1255.0ms, RTF: 0.126)[0m
[32m[INFO] 22:27:12.336 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:12.360 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:12.463 asr_benchmark.c:102:     Loaded WAV: test_027.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:12.463 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:12.605 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:12.605 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:13.824 asr_whisper.c:256:       Whisper: Final result: " Friday, I need you to turn on the living room lights." (1218.9ms, RTF: 0.122)[0m
[32m[INFO] 22:27:13.824 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:13.850 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:13.954 asr_benchmark.c:102:     Loaded WAV: test_028.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:13.954 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:14.099 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:14.099 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:15.342 asr_whisper.c:256:       Whisper: Final result: " Friday, could you please tell me what the weather is like today?" (1243.0ms, RTF: 0.124)[0m
[32m[INFO] 22:27:15.343 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:15.368 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:15.473 asr_benchmark.c:102:     Loaded WAV: test_029.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:15.473 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:15.616 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:15.616 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:16.864 asr_whisper.c:256:       Whisper: Final result: " Friday, set a timer for 10 minutes from now." (1248.2ms, RTF: 0.125)[0m
[32m[INFO] 22:27:16.865 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:16.890 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:16.994 asr_benchmark.c:102:     Loaded WAV: test_030.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:16.994 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:17.137 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:17.137 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:18.352 asr_whisper.c:256:       Whisper: Final result: " Friday, what is the status of the Oasis Project?" (1214.9ms, RTF: 0.121)[0m
[32m[INFO] 22:27:18.352 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:18.377 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:18.492 asr_benchmark.c:102:     Loaded WAV: test_031.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:18.492 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:18.658 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:18.658 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:19.888 asr_whisper.c:256:       Whisper: Final result: " Friday, turn on the lights in the bedroom and kitchen." (1229.2ms, RTF: 0.123)[0m
[32m[INFO] 22:27:19.888 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:19.914 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:20.018 asr_benchmark.c:102:     Loaded WAV: test_032.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:20.018 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:20.164 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:20.165 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:21.370 asr_whisper.c:256:       Whisper: Final result: " Friday, can you give me an update on the system status?" (1205.2ms, RTF: 0.121)[0m
[32m[INFO] 22:27:21.370 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:21.396 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:21.504 asr_benchmark.c:102:     Loaded WAV: test_033.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:21.504 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:21.646 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:21.646 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:22.926 asr_whisper.c:256:       Whisper: Final result: " Friday, I'm going to do a little bit of testing." (1279.0ms, RTF: 0.128)[0m
[32m[INFO] 22:27:22.926 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:22.951 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:23.056 asr_benchmark.c:102:     Loaded WAV: test_034.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:23.056 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:23.197 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:23.197 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:24.478 asr_whisper.c:256:       Whisper: Final result: " Friday remind me to check the server logs later." (1281.1ms, RTF: 0.128)[0m
[32m[INFO] 22:27:24.478 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:24.504 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:24.607 asr_benchmark.c:102:     Loaded WAV: test_035.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:24.607 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:24.760 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:24.760 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:25.973 asr_whisper.c:256:       Whisper: Final result: " Friday, what were the results of the last benchmark?" (1212.1ms, RTF: 0.121)[0m
[32m[INFO] 22:27:25.973 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:25.998 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:26.102 asr_benchmark.c:102:     Loaded WAV: test_036.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:26.102 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:26.243 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:26.243 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:27.531 asr_whisper.c:256:       Whisper: Final result: " Friday, can you explain how the ASR system works?" (1287.5ms, RTF: 0.129)[0m
[32m[INFO] 22:27:27.531 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:27.559 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:27.674 asr_benchmark.c:102:     Loaded WAV: test_037.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:27.674 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:27.822 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:27.822 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:29.058 asr_whisper.c:256:       Whisper: Final result: " Friday show me the current CPU and memory usage." (1235.3ms, RTF: 0.124)[0m
[32m[INFO] 22:27:29.058 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:29.084 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:29.192 asr_benchmark.c:102:     Loaded WAV: test_038.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:29.192 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:29.334 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:29.334 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:30.563 asr_whisper.c:256:       Whisper: Final result: " Friday, I need help troubleshooting a network issue." (1228.1ms, RTF: 0.123)[0m
[32m[INFO] 22:27:30.563 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:30.588 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:30.696 asr_benchmark.c:102:     Loaded WAV: test_039.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:30.696 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:30.840 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:30.840 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:32.046 asr_whisper.c:256:       Whisper: Final result: " What sensors are currently active in the house?" (1205.7ms, RTF: 0.121)[0m
[32m[INFO] 22:27:32.046 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:32.078 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:32.186 asr_benchmark.c:102:     Loaded WAV: test_040.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:27:32.186 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:32.325 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:32.325 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:33.608 asr_whisper.c:256:       Whisper: Final result: " Friday, give me a summary of today's activities." (1283.2ms, RTF: 0.128)[0m
[32m[INFO] 22:27:33.609 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:33.634 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:33.743 asr_benchmark.c:102:     Loaded WAV: test_041.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:33.743 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:33.884 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:33.884 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:35.228 asr_whisper.c:256:       Whisper: Final result: " Friday, I'm going to do a little bit of testing just to see how my new text to speech ASR is working and we're going to go ahead and run some benchmarks." (1343.9ms, RTF: 0.090)[0m
[32m[INFO] 22:27:35.228 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:35.254 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:35.376 asr_benchmark.c:102:     Loaded WAV: test_042.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:35.376 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:35.522 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:35.522 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:36.868 asr_whisper.c:256:       Whisper: Final result: " Friday, can you tell me about the Oasis Project specs, including Mirage, Dawn, Orra and Spark, and what each component does?" (1344.7ms, RTF: 0.090)[0m
[32m[INFO] 22:27:36.868 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:36.893 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:37.002 asr_benchmark.c:102:     Loaded WAV: test_043.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:37.002 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:37.145 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:37.146 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:38.542 asr_whisper.c:256:       Whisper: Final result: " Friday, I need you to analyze the recent performance metrics and let me know if there are any anomalies or issues that need attention." (1395.8ms, RTF: 0.093)[0m
[32m[INFO] 22:27:38.542 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:38.568 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:38.676 asr_benchmark.c:102:     Loaded WAV: test_044.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:38.676 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:38.825 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:38.825 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:40.109 asr_whisper.c:256:       Whisper: Final result: " Friday, could you please walk me through the steps to configure a new sensor and integrate it with the existing home automation system?" (1283.6ms, RTF: 0.086)[0m
[32m[INFO] 22:27:40.109 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:40.134 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:40.238 asr_benchmark.c:102:     Loaded WAV: test_045.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:40.238 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:40.381 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:40.381 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:41.679 asr_whisper.c:256:       Whisper: Final result: " Friday, I'm experiencing some latency issues with the voice recognition and I'm wondering if it might be related to network bandwidth or processing power." (1297.5ms, RTF: 0.087)[0m
[32m[INFO] 22:27:41.679 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:41.706 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:41.813 asr_benchmark.c:102:     Loaded WAV: test_046.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:41.813 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:41.955 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:41.955 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:43.242 asr_whisper.c:256:       Whisper: Final result: " Friday, give me a detailed breakdown of the energy consumption across all connected devices for the past week and highlight any unusual patterns." (1286.5ms, RTF: 0.086)[0m
[32m[INFO] 22:27:43.242 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:43.268 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:43.372 asr_benchmark.c:102:     Loaded WAV: test_047.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:43.372 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:43.516 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:43.516 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:44.863 asr_whisper.c:256:       Whisper: Final result: " Friday, I want to set up an automation routine that turns on the lights when I arrive home and adjust the thermostat based on the current weather." (1345.8ms, RTF: 0.090)[0m
[32m[INFO] 22:27:44.863 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:44.889 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:44.996 asr_benchmark.c:102:     Loaded WAV: test_048.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:44.996 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:45.136 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:45.136 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:46.586 asr_whisper.c:256:       Whisper: Final result: " Friday, can you compare the performance of VOSC versus Whisper for Speedtruck Ignition Accuracy, Real Time Factor, and Overall System Resource Usage?" (1449.1ms, RTF: 0.097)[0m
[32m[INFO] 22:27:46.586 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:46.612 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:46.720 asr_benchmark.c:102:     Loaded WAV: test_049.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:46.720 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:46.869 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:46.869 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:48.263 asr_whisper.c:256:       Whisper: Final result: " For today, I need to know if the backup systems are functioning properly and when the last successful backup was completed for all critical data." (1393.6ms, RTF: 0.093)[0m
[32m[INFO] 22:27:48.263 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:48.289 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:48.394 asr_benchmark.c:102:     Loaded WAV: test_050.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:27:48.394 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-tiny.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 384
whisper_model_load: n_audio_head  = 6
whisper_model_load: n_audio_layer = 4
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 384
whisper_model_load: n_text_head   = 6
whisper_model_load: n_text_layer  = 4
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 1 (tiny)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =    77.11 MB
whisper_model_load: model size    =   77.11 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    3.15 MB
whisper_init_state: kv cross size =    9.44 MB
whisper_init_state: kv pad  size  =    2.36 MB
whisper_init_state: compute buffer (conv)   =   13.21 MB
whisper_init_state: compute buffer (encode) =   17.72 MB
whisper_init_state: compute buffer (cross)  =    3.89 MB
whisper_init_state: compute buffer (decode) =   95.91 MB
[32m[INFO] 22:27:48.538 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-tiny.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:48.538 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:49.831 asr_whisper.c:256:       Whisper: Final result: " Friday, please explain the difference between streaming ASR and batch processing and how that affects the responsiveness of the voice assistant." (1292.7ms, RTF: 0.086)[0m
[32m[INFO] 22:27:49.831 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:49.857 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:49.971 asr_benchmark.c:102:     Loaded WAV: test_001.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:49.971 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:27:50.257 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:50.257 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:52.695 asr_whisper.c:256:       Whisper: Final result: " Friday." (2438.3ms, RTF: 0.488)[0m
[32m[INFO] 22:27:52.695 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:52.720 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:52.838 asr_benchmark.c:102:     Loaded WAV: test_002.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:52.838 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:27:53.039 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:53.039 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:55.668 asr_whisper.c:256:       Whisper: Final result: " Okay Friday." (2629.1ms, RTF: 0.526)[0m
[32m[INFO] 22:27:55.668 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:55.693 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:55.806 asr_benchmark.c:102:     Loaded WAV: test_003.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:55.806 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:27:55.996 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:55.996 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:27:58.720 asr_whisper.c:256:       Whisper: Final result: " Hey Friday." (2723.4ms, RTF: 0.545)[0m
[32m[INFO] 22:27:58.720 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:27:58.746 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:27:58.850 asr_benchmark.c:102:     Loaded WAV: test_004.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:27:58.851 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:27:59.029 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:27:59.029 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:01.537 asr_whisper.c:256:       Whisper: Final result: " Friday or you there?" (2507.1ms, RTF: 0.501)[0m
[32m[INFO] 22:28:01.537 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:01.563 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:01.679 asr_benchmark.c:102:     Loaded WAV: test_005.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:01.680 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:01.901 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:01.901 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:04.424 asr_whisper.c:256:       Whisper: Final result: " Okay, Friday are you listening?" (2522.6ms, RTF: 0.505)[0m
[32m[INFO] 22:28:04.424 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:04.464 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:04.561 asr_benchmark.c:102:     Loaded WAV: test_006.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:04.561 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:04.752 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:04.752 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:07.191 asr_whisper.c:256:       Whisper: Final result: " Friday." (2439.0ms, RTF: 0.488)[0m
[32m[INFO] 22:28:07.191 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:07.216 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:07.322 asr_benchmark.c:102:     Loaded WAV: test_007.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:07.322 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:07.505 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:07.505 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:10.003 asr_whisper.c:256:       Whisper: Final result: " Friday." (2497.8ms, RTF: 0.500)[0m
[32m[INFO] 22:28:10.003 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:10.029 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:10.134 asr_benchmark.c:102:     Loaded WAV: test_008.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:10.134 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:10.312 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:10.312 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:12.822 asr_whisper.c:256:       Whisper: Final result: " Friday, what time is it?" (2509.5ms, RTF: 0.502)[0m
[32m[INFO] 22:28:12.822 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:12.848 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:12.951 asr_benchmark.c:102:     Loaded WAV: test_009.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:12.951 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:13.131 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:13.131 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:15.678 asr_whisper.c:256:       Whisper: Final result: " Okay Friday, are you there?" (2546.4ms, RTF: 0.509)[0m
[32m[INFO] 22:28:15.678 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:15.720 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:15.809 asr_benchmark.c:102:     Loaded WAV: test_010.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:15.809 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:15.992 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:15.992 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:18.579 asr_whisper.c:256:       Whisper: Final result: " Friday." (2586.1ms, RTF: 0.517)[0m
[32m[INFO] 22:28:18.579 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:18.604 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:18.706 asr_benchmark.c:102:     Loaded WAV: test_011.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:18.707 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:18.891 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:18.891 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:21.403 asr_whisper.c:256:       Whisper: Final result: " Friday, what time is it?" (2511.6ms, RTF: 0.502)[0m
[32m[INFO] 22:28:21.403 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:21.446 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:21.535 asr_benchmark.c:102:     Loaded WAV: test_012.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:21.535 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:21.718 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:21.718 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:24.330 asr_whisper.c:256:       Whisper: Final result: " Friday turn on the lights." (2612.2ms, RTF: 0.522)[0m
[32m[INFO] 22:28:24.331 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:24.357 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:24.459 asr_benchmark.c:102:     Loaded WAV: test_013.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:24.459 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:24.640 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:24.640 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:27.131 asr_whisper.c:256:       Whisper: Final result: " Friday, turn off the lights." (2490.1ms, RTF: 0.498)[0m
[32m[INFO] 22:28:27.131 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:27.171 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:27.270 asr_benchmark.c:102:     Loaded WAV: test_014.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:27.270 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:27.451 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:27.451 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:29.974 asr_whisper.c:256:       Whisper: Final result: " Friday, watch the weather." (2523.0ms, RTF: 0.505)[0m
[32m[INFO] 22:28:29.975 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:30.000 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:30.104 asr_benchmark.c:102:     Loaded WAV: test_015.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:30.104 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:30.291 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:30.291 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:32.760 asr_whisper.c:256:       Whisper: Final result: " Friday set a timer." (2468.6ms, RTF: 0.494)[0m
[32m[INFO] 22:28:32.760 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:32.810 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:32.905 asr_benchmark.c:102:     Loaded WAV: test_016.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:32.905 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:33.088 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:33.088 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:35.659 asr_whisper.c:256:       Whisper: Final result: " Friday, good morning." (2570.5ms, RTF: 0.514)[0m
[32m[INFO] 22:28:35.659 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:35.700 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:35.789 asr_benchmark.c:102:     Loaded WAV: test_017.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:35.789 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:35.973 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:35.973 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:38.569 asr_whisper.c:256:       Whisper: Final result: " Friday Good Night." (2595.4ms, RTF: 0.519)[0m
[32m[INFO] 22:28:38.569 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:38.594 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:38.697 asr_benchmark.c:102:     Loaded WAV: test_018.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:38.697 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:38.884 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:38.884 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:41.348 asr_whisper.c:256:       Whisper: Final result: " Friday, thank you." (2464.2ms, RTF: 0.493)[0m
[32m[INFO] 22:28:41.349 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:41.374 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:41.480 asr_benchmark.c:102:     Loaded WAV: test_019.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:41.480 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:41.663 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:41.663 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:44.108 asr_whisper.c:256:       Whisper: Final result: " Friday help me." (2444.9ms, RTF: 0.489)[0m
[32m[INFO] 22:28:44.108 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:44.133 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:44.239 asr_benchmark.c:102:     Loaded WAV: test_020.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:44.239 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:44.423 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:44.423 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:46.907 asr_whisper.c:256:       Whisper: Final result: " Friday, stop." (2483.1ms, RTF: 0.497)[0m
[32m[INFO] 22:28:46.907 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:46.932 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:47.037 asr_benchmark.c:102:     Loaded WAV: test_021.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:47.037 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:47.220 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:47.220 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:49.660 asr_whisper.c:256:       Whisper: Final result: " Friday pause." (2439.8ms, RTF: 0.488)[0m
[32m[INFO] 22:28:49.660 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:49.686 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:49.793 asr_benchmark.c:102:     Loaded WAV: test_022.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:49.793 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:49.978 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:49.978 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:52.421 asr_whisper.c:256:       Whisper: Final result: " Friday resume." (2443.2ms, RTF: 0.489)[0m
[32m[INFO] 22:28:52.422 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:52.447 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:52.551 asr_benchmark.c:102:     Loaded WAV: test_023.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:52.551 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:52.734 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:52.734 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:55.349 asr_whisper.c:256:       Whisper: Final result: " Friday, volume up." (2615.3ms, RTF: 0.523)[0m
[32m[INFO] 22:28:55.349 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:55.375 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:55.479 asr_benchmark.c:102:     Loaded WAV: test_024.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:55.480 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:55.661 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:55.661 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:28:58.185 asr_whisper.c:256:       Whisper: Final result: " Friday, volume down." (2524.1ms, RTF: 0.505)[0m
[32m[INFO] 22:28:58.186 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:28:58.211 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:28:58.315 asr_benchmark.c:102:     Loaded WAV: test_025.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:28:58.316 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:28:58.499 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:28:58.499 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:01.020 asr_whisper.c:256:       Whisper: Final result: " Friday, what can you do?" (2519.9ms, RTF: 0.504)[0m
[32m[INFO] 22:29:01.020 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:01.058 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:01.147 asr_benchmark.c:102:     Loaded WAV: test_026.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:01.147 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:01.330 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:01.330 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:03.853 asr_whisper.c:256:       Whisper: Final result: " Friday, can you tell me what the current time is please?" (2522.5ms, RTF: 0.252)[0m
[32m[INFO] 22:29:03.854 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:03.898 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:03.990 asr_benchmark.c:102:     Loaded WAV: test_027.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:03.990 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:04.175 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:04.175 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:06.708 asr_whisper.c:256:       Whisper: Final result: " Friday, I need you to turn on the living room lights." (2532.4ms, RTF: 0.253)[0m
[32m[INFO] 22:29:06.708 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:06.734 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:06.839 asr_benchmark.c:102:     Loaded WAV: test_028.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:06.840 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:07.022 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:07.022 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:09.583 asr_whisper.c:256:       Whisper: Final result: " Friday, could you please tell me what the weather is like today?" (2560.4ms, RTF: 0.256)[0m
[32m[INFO] 22:29:09.583 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:09.625 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:09.716 asr_benchmark.c:102:     Loaded WAV: test_029.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:09.716 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:09.905 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:09.905 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:12.527 asr_whisper.c:256:       Whisper: Final result: " Friday, set a timer for 10 minutes from now." (2621.2ms, RTF: 0.262)[0m
[32m[INFO] 22:29:12.527 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:12.567 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:12.665 asr_benchmark.c:102:     Loaded WAV: test_030.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:12.665 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:12.847 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:12.847 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:15.404 asr_whisper.c:256:       Whisper: Final result: " Friday, what is the status of the OASIS project?" (2556.0ms, RTF: 0.256)[0m
[32m[INFO] 22:29:15.404 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:15.430 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:15.533 asr_benchmark.c:102:     Loaded WAV: test_031.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:15.533 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:15.714 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:15.714 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:18.231 asr_whisper.c:256:       Whisper: Final result: " Friday, turn on the lights in the bedroom and kitchen." (2517.0ms, RTF: 0.252)[0m
[32m[INFO] 22:29:18.231 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:18.257 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:18.362 asr_benchmark.c:102:     Loaded WAV: test_032.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:18.362 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:18.547 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:18.548 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:21.059 asr_whisper.c:256:       Whisper: Final result: " Friday, can you give me an update on the system status?" (2510.6ms, RTF: 0.251)[0m
[32m[INFO] 22:29:21.059 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:21.102 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:21.192 asr_benchmark.c:102:     Loaded WAV: test_033.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:21.192 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:21.373 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:21.373 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:23.929 asr_whisper.c:256:       Whisper: Final result: " Friday, I'm going to do a little bit of testing." (2555.8ms, RTF: 0.256)[0m
[32m[INFO] 22:29:23.929 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:23.971 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:24.060 asr_benchmark.c:102:     Loaded WAV: test_034.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:24.060 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:24.240 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:24.240 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:26.736 asr_whisper.c:256:       Whisper: Final result: " Friday remind me to check the server logs later." (2495.4ms, RTF: 0.250)[0m
[32m[INFO] 22:29:26.736 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:26.761 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:26.870 asr_benchmark.c:102:     Loaded WAV: test_035.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:26.871 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:27.057 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:27.057 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:29.564 asr_whisper.c:256:       Whisper: Final result: " Friday, what were the results of the last benchmark?" (2506.4ms, RTF: 0.251)[0m
[32m[INFO] 22:29:29.564 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:29.606 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:29.693 asr_benchmark.c:102:     Loaded WAV: test_036.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:29.693 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:29.877 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:29.877 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:32.393 asr_whisper.c:256:       Whisper: Final result: " Friday, can you explain how the ASR system works?" (2516.0ms, RTF: 0.252)[0m
[32m[INFO] 22:29:32.393 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:32.419 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:32.524 asr_benchmark.c:102:     Loaded WAV: test_037.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:32.524 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:32.706 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:32.706 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:35.212 asr_whisper.c:256:       Whisper: Final result: " Friday, show me the current CPU and memory usage." (2506.0ms, RTF: 0.251)[0m
[32m[INFO] 22:29:35.212 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:35.253 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:35.342 asr_benchmark.c:102:     Loaded WAV: test_038.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:35.342 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:35.528 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:35.528 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:38.252 asr_whisper.c:256:       Whisper: Final result: " Friday, I need help troubleshooting a network issue." (2723.4ms, RTF: 0.272)[0m
[32m[INFO] 22:29:38.252 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:38.278 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:38.385 asr_benchmark.c:102:     Loaded WAV: test_039.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:38.385 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:38.572 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:38.572 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:41.268 asr_whisper.c:256:       Whisper: Final result: " Friday, what sensors are currently active in the house?" (2695.7ms, RTF: 0.270)[0m
[32m[INFO] 22:29:41.268 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:41.310 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:41.398 asr_benchmark.c:102:     Loaded WAV: test_040.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:29:41.398 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:41.587 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:41.587 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:44.080 asr_whisper.c:256:       Whisper: Final result: " Friday, give me a summary of today's activities." (2492.8ms, RTF: 0.249)[0m
[32m[INFO] 22:29:44.080 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:44.123 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:44.211 asr_benchmark.c:102:     Loaded WAV: test_041.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:29:44.211 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:44.394 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:44.394 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:47.160 asr_whisper.c:256:       Whisper: Final result: " Friday, I'm going to do a little bit of testing just to see how my new text to speech ASR is working. And we're going to go ahead and run some benchmarks." (2766.0ms, RTF: 0.184)[0m
[32m[INFO] 22:29:47.161 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:47.203 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:47.295 asr_benchmark.c:102:     Loaded WAV: test_042.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:29:47.295 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:47.480 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:47.480 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:50.179 asr_whisper.c:256:       Whisper: Final result: " Friday, can you tell me about the OASIS project, specs, including Mirage, Dawn, Aura, and Spark, and what each component does?" (2698.8ms, RTF: 0.180)[0m
[32m[INFO] 22:29:50.180 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:50.205 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:50.312 asr_benchmark.c:102:     Loaded WAV: test_043.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:29:50.313 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:50.496 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:50.496 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:53.328 asr_whisper.c:256:       Whisper: Final result: " Friday, I need you to analyze the recent performance metrics and let me know if there are any anomalies or issues that need attention." (2830.9ms, RTF: 0.189)[0m
[32m[INFO] 22:29:53.328 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:53.354 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:53.460 asr_benchmark.c:102:     Loaded WAV: test_044.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:29:53.460 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:53.643 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:53.644 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:56.345 asr_whisper.c:256:       Whisper: Final result: " Friday, could you please walk me through the steps to configure a new sensor and integrate it with the existing home automation system?" (2701.3ms, RTF: 0.180)[0m
[32m[INFO] 22:29:56.346 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:56.387 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:56.475 asr_benchmark.c:102:     Loaded WAV: test_045.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:29:56.475 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:56.657 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:56.657 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:29:59.476 asr_whisper.c:256:       Whisper: Final result: " Friday, I'm experiencing some latency issues with the voice recognition and I'm wondering if it might be related to network bandwidth or processing power." (2818.3ms, RTF: 0.188)[0m
[32m[INFO] 22:29:59.476 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:29:59.502 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:29:59.609 asr_benchmark.c:102:     Loaded WAV: test_046.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:29:59.610 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:29:59.791 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:29:59.791 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:30:02.430 asr_whisper.c:256:       Whisper: Final result: " Friday, give me a detailed breakdown of the energy consumption across all connected devices for the past week and highlight any unusual patterns." (2638.2ms, RTF: 0.176)[0m
[32m[INFO] 22:30:02.430 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:30:02.456 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:30:02.563 asr_benchmark.c:102:     Loaded WAV: test_047.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:30:02.563 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:30:02.751 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:30:02.751 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:30:05.412 asr_whisper.c:256:       Whisper: Final result: " Friday, I want to set up an automation routine that turns on the lights when I arrive home and adjust the thermostat based on the current weather." (2660.6ms, RTF: 0.177)[0m
[32m[INFO] 22:30:05.413 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:30:05.455 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:30:05.545 asr_benchmark.c:102:     Loaded WAV: test_048.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:30:05.545 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:30:05.729 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:30:05.729 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:30:08.495 asr_whisper.c:256:       Whisper: Final result: " Friday, can you compare the performance of VOSC versus Whisper for speech recognition accuracy, real-time factor, and overall system resource usage?" (2765.4ms, RTF: 0.184)[0m
[32m[INFO] 22:30:08.495 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:30:08.539 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:30:08.638 asr_benchmark.c:102:     Loaded WAV: test_049.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:30:08.638 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:30:08.826 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:30:08.826 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:30:11.485 asr_whisper.c:256:       Whisper: Final result: " Friday, I need to know if the backup systems are functioning properly and when the last successful backup was completed for all critical data." (2658.5ms, RTF: 0.177)[0m
[32m[INFO] 22:30:11.485 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:30:11.511 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:30:11.619 asr_benchmark.c:102:     Loaded WAV: test_050.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:30:11.619 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-base.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 2 (base)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   147.37 MB
whisper_model_load: model size    =  147.37 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =    6.29 MB
whisper_init_state: kv cross size =   18.87 MB
whisper_init_state: kv pad  size  =    3.15 MB
whisper_init_state: compute buffer (conv)   =   16.28 MB
whisper_init_state: compute buffer (encode) =   23.09 MB
whisper_init_state: compute buffer (cross)  =    4.66 MB
whisper_init_state: compute buffer (decode) =   96.37 MB
[32m[INFO] 22:30:11.801 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-base.bin, sample_rate: 16000)[0m
[32m[INFO] 22:30:11.802 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:30:14.432 asr_whisper.c:256:       Whisper: Final result: " Friday, please explain the difference between streaming ASR and batch processing and how that affects the responsiveness of the voice assistant." (2629.3ms, RTF: 0.175)[0m
[32m[INFO] 22:30:14.432 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:30:14.477 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:30:14.580 asr_benchmark.c:102:     Loaded WAV: test_001.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:30:14.580 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:30:15.122 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:30:15.122 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:30:23.571 asr_whisper.c:256:       Whisper: Final result: " Friday." (8449.3ms, RTF: 1.690)[0m
[32m[INFO] 22:30:23.571 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:30:23.598 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:30:23.705 asr_benchmark.c:102:     Loaded WAV: test_002.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:30:23.705 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:30:24.066 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:30:24.066 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:30:32.648 asr_whisper.c:256:       Whisper: Final result: " Okay, Friday." (8581.3ms, RTF: 1.716)[0m
[32m[INFO] 22:30:32.648 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:30:32.674 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:30:32.782 asr_benchmark.c:102:     Loaded WAV: test_003.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:30:32.782 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:30:33.121 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:30:33.121 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:30:42.320 asr_whisper.c:256:       Whisper: Final result: " Hey Friday." (9198.6ms, RTF: 1.840)[0m
[32m[INFO] 22:30:42.320 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:30:42.345 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:30:42.449 asr_benchmark.c:102:     Loaded WAV: test_004.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:30:42.449 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:30:42.777 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:30:42.777 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:30:51.403 asr_whisper.c:256:       Whisper: Final result: " Friday, are you there?" (8625.5ms, RTF: 1.725)[0m
[32m[INFO] 22:30:51.403 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:30:51.428 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:30:51.534 asr_benchmark.c:102:     Loaded WAV: test_005.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:30:51.535 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:30:51.858 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:30:51.858 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:31:00.456 asr_whisper.c:256:       Whisper: Final result: " Okay, Friday, are you listening?" (8598.2ms, RTF: 1.720)[0m
[32m[INFO] 22:31:00.457 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:31:00.500 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:31:00.590 asr_benchmark.c:102:     Loaded WAV: test_006.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:31:00.590 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:31:00.918 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:31:00.918 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:31:09.554 asr_whisper.c:256:       Whisper: Final result: " Friday." (8635.1ms, RTF: 1.727)[0m
[32m[INFO] 22:31:09.554 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:31:09.580 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:31:09.684 asr_benchmark.c:102:     Loaded WAV: test_007.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:31:09.684 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:31:10.010 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:31:10.010 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:31:18.715 asr_whisper.c:256:       Whisper: Final result: " Friday." (8704.8ms, RTF: 1.741)[0m
[32m[INFO] 22:31:18.715 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:31:18.742 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:31:18.845 asr_benchmark.c:102:     Loaded WAV: test_008.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:31:18.845 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:31:19.173 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:31:19.173 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:31:27.749 asr_whisper.c:256:       Whisper: Final result: " Friday, what time is it?" (8575.2ms, RTF: 1.715)[0m
[32m[INFO] 22:31:27.749 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:31:27.790 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:31:27.877 asr_benchmark.c:102:     Loaded WAV: test_009.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:31:27.877 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:31:28.206 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:31:28.206 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:31:36.951 asr_whisper.c:256:       Whisper: Final result: " Okay Friday, are you there?" (8745.0ms, RTF: 1.749)[0m
[32m[INFO] 22:31:36.951 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:31:36.978 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:31:37.082 asr_benchmark.c:102:     Loaded WAV: test_010.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:31:37.083 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:31:37.407 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:31:37.407 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:31:46.344 asr_whisper.c:256:       Whisper: Final result: " Friday." (8936.6ms, RTF: 1.787)[0m
[32m[INFO] 22:31:46.344 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:31:46.369 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:31:46.472 asr_benchmark.c:102:     Loaded WAV: test_011.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:31:46.472 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:31:46.800 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:31:46.800 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:31:55.521 asr_whisper.c:256:       Whisper: Final result: " Friday, what time is it?" (8720.7ms, RTF: 1.744)[0m
[32m[INFO] 22:31:55.521 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:31:55.564 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:31:55.659 asr_benchmark.c:102:     Loaded WAV: test_012.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:31:55.659 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:31:55.981 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:31:55.982 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:32:04.601 asr_whisper.c:256:       Whisper: Final result: " Friday, turn on the lights." (8618.7ms, RTF: 1.724)[0m
[32m[INFO] 22:32:04.601 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:32:04.628 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:32:04.735 asr_benchmark.c:102:     Loaded WAV: test_013.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:32:04.735 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:32:05.067 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:32:05.067 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:32:13.690 asr_whisper.c:256:       Whisper: Final result: " Friday, turn off the lights." (8622.3ms, RTF: 1.724)[0m
[32m[INFO] 22:32:13.690 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:32:13.717 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:32:13.823 asr_benchmark.c:102:     Loaded WAV: test_014.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:32:13.824 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:32:14.151 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:32:14.151 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:32:22.674 asr_whisper.c:256:       Whisper: Final result: " Friday, what's the weather?" (8522.9ms, RTF: 1.705)[0m
[32m[INFO] 22:32:22.674 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:32:22.716 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:32:22.802 asr_benchmark.c:102:     Loaded WAV: test_015.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:32:22.802 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:32:23.128 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:32:23.128 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:32:31.679 asr_whisper.c:256:       Whisper: Final result: " Friday set of timer." (8550.6ms, RTF: 1.710)[0m
[32m[INFO] 22:32:31.679 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:32:31.706 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:32:31.821 asr_benchmark.c:102:     Loaded WAV: test_016.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:32:31.821 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:32:32.156 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:32:32.156 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:32:40.764 asr_whisper.c:256:       Whisper: Final result: " Friday, good morning." (8607.1ms, RTF: 1.721)[0m
[32m[INFO] 22:32:40.764 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:32:40.791 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:32:40.895 asr_benchmark.c:102:     Loaded WAV: test_017.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:32:40.895 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:32:41.222 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:32:41.222 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:32:49.825 asr_whisper.c:256:       Whisper: Final result: " Friday, good night." (8602.9ms, RTF: 1.721)[0m
[32m[INFO] 22:32:49.825 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:32:49.852 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:32:49.958 asr_benchmark.c:102:     Loaded WAV: test_018.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:32:49.958 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:32:50.288 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:32:50.288 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:32:58.867 asr_whisper.c:256:       Whisper: Final result: " Friday, thank you." (8578.6ms, RTF: 1.716)[0m
[32m[INFO] 22:32:58.867 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:32:58.894 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:32:59.004 asr_benchmark.c:102:     Loaded WAV: test_019.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:32:59.005 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:32:59.334 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:32:59.334 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:33:07.895 asr_whisper.c:256:       Whisper: Final result: " Friday, help me." (8560.9ms, RTF: 1.712)[0m
[32m[INFO] 22:33:07.896 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:33:07.922 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:33:08.029 asr_benchmark.c:102:     Loaded WAV: test_020.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:33:08.029 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:33:08.351 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:33:08.351 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:33:16.915 asr_whisper.c:256:       Whisper: Final result: " Friday, stop." (8563.7ms, RTF: 1.713)[0m
[32m[INFO] 22:33:16.915 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:33:16.941 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:33:17.045 asr_benchmark.c:102:     Loaded WAV: test_021.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:33:17.046 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:33:17.373 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:33:17.373 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:33:25.913 asr_whisper.c:256:       Whisper: Final result: " Friday, pause." (8539.9ms, RTF: 1.708)[0m
[32m[INFO] 22:33:25.913 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:33:25.939 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:33:26.044 asr_benchmark.c:102:     Loaded WAV: test_022.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:33:26.044 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:33:26.377 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:33:26.377 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:33:34.957 asr_whisper.c:256:       Whisper: Final result: " Friday, resume." (8579.3ms, RTF: 1.716)[0m
[32m[INFO] 22:33:34.957 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:33:34.984 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:33:35.089 asr_benchmark.c:102:     Loaded WAV: test_023.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:33:35.089 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:33:35.412 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:33:35.413 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:33:43.953 asr_whisper.c:256:       Whisper: Final result: " Friday volume up." (8540.5ms, RTF: 1.708)[0m
[32m[INFO] 22:33:43.953 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:33:43.979 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:33:44.081 asr_benchmark.c:102:     Loaded WAV: test_024.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:33:44.081 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:33:44.401 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:33:44.401 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:33:52.904 asr_whisper.c:256:       Whisper: Final result: " Friday volume down." (8502.3ms, RTF: 1.700)[0m
[32m[INFO] 22:33:52.904 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:33:52.930 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:33:53.038 asr_benchmark.c:102:     Loaded WAV: test_025.wav (80000 samples, 16000 Hz, 5.00 seconds)[0m
[32m[INFO] 22:33:53.038 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:33:53.369 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:33:53.369 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:34:01.989 asr_whisper.c:256:       Whisper: Final result: " Friday, what can you do?" (8620.0ms, RTF: 1.724)[0m
[32m[INFO] 22:34:01.990 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:34:02.016 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:34:02.122 asr_benchmark.c:102:     Loaded WAV: test_026.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:34:02.122 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:34:02.449 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:34:02.449 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:34:11.150 asr_whisper.c:256:       Whisper: Final result: " Friday, can you tell me what the current time is please?" (8700.5ms, RTF: 0.870)[0m
[32m[INFO] 22:34:11.150 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:34:11.186 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:34:11.273 asr_benchmark.c:102:     Loaded WAV: test_027.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:34:11.274 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:34:11.599 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:34:11.599 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:34:20.516 asr_whisper.c:256:       Whisper: Final result: " Friday, I need you to turn on the living room lights." (8915.8ms, RTF: 0.892)[0m
[32m[INFO] 22:34:20.516 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:34:20.559 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:34:20.648 asr_benchmark.c:102:     Loaded WAV: test_028.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:34:20.648 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:34:20.977 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:34:20.977 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:34:29.639 asr_whisper.c:256:       Whisper: Final result: " Friday, could you please tell me what the weather is like today?" (8661.5ms, RTF: 0.866)[0m
[32m[INFO] 22:34:29.640 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:34:29.673 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:34:29.759 asr_benchmark.c:102:     Loaded WAV: test_029.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:34:29.759 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:34:30.099 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:34:30.100 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:34:38.758 asr_whisper.c:256:       Whisper: Final result: " Friday, set a timer for 10 minutes from now." (8658.4ms, RTF: 0.866)[0m
[32m[INFO] 22:34:38.759 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:34:38.780 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:34:38.880 asr_benchmark.c:102:     Loaded WAV: test_030.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:34:38.880 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:34:39.205 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:34:39.206 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:34:47.867 asr_whisper.c:256:       Whisper: Final result: " Friday, what is the status of the OASIS project?" (8660.8ms, RTF: 0.866)[0m
[32m[INFO] 22:34:47.867 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:34:47.888 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:34:47.988 asr_benchmark.c:102:     Loaded WAV: test_031.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:34:47.988 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:34:48.318 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:34:48.318 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:34:56.954 asr_whisper.c:256:       Whisper: Final result: " Friday, turn on the lights in the bedroom and kitchen." (8635.6ms, RTF: 0.864)[0m
[32m[INFO] 22:34:56.954 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:34:56.975 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:34:57.077 asr_benchmark.c:102:     Loaded WAV: test_032.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:34:57.077 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:34:57.414 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:34:57.414 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:35:06.183 asr_whisper.c:256:       Whisper: Final result: " Friday, can you give me an update on the system status?" (8768.5ms, RTF: 0.877)[0m
[32m[INFO] 22:35:06.184 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:35:06.228 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:35:06.319 asr_benchmark.c:102:     Loaded WAV: test_033.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:35:06.319 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:35:06.646 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:35:06.646 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:35:15.474 asr_whisper.c:256:       Whisper: Final result: " Friday, I'm going to do a little bit of testing." (8827.6ms, RTF: 0.883)[0m
[32m[INFO] 22:35:15.474 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:35:15.518 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:35:15.606 asr_benchmark.c:102:     Loaded WAV: test_034.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:35:15.606 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:35:15.930 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:35:15.930 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:35:24.676 asr_whisper.c:256:       Whisper: Final result: " Friday, remind me to check the server logs later." (8745.8ms, RTF: 0.875)[0m
[32m[INFO] 22:35:24.677 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:35:24.698 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:35:24.795 asr_benchmark.c:102:     Loaded WAV: test_035.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:35:24.796 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:35:25.120 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:35:25.120 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:35:33.875 asr_whisper.c:256:       Whisper: Final result: " Friday, what were the results of the last benchmark?" (8755.4ms, RTF: 0.876)[0m
[32m[INFO] 22:35:33.876 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:35:33.910 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:35:34.003 asr_benchmark.c:102:     Loaded WAV: test_036.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:35:34.003 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:35:34.386 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:35:34.386 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:35:43.246 asr_whisper.c:256:       Whisper: Final result: " Friday, can you explain how the ASR system works?" (8859.6ms, RTF: 0.886)[0m
[32m[INFO] 22:35:43.246 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:35:43.289 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:35:43.377 asr_benchmark.c:102:     Loaded WAV: test_037.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:35:43.377 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:35:43.699 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:35:43.699 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:35:52.396 asr_whisper.c:256:       Whisper: Final result: " Friday, show me the current CPU and memory usage." (8697.2ms, RTF: 0.870)[0m
[32m[INFO] 22:35:52.397 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:35:52.429 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:35:52.514 asr_benchmark.c:102:     Loaded WAV: test_038.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:35:52.514 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:35:52.840 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:35:52.840 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:36:01.557 asr_whisper.c:256:       Whisper: Final result: " Friday, I need help troubleshooting a network issue." (8716.6ms, RTF: 0.872)[0m
[32m[INFO] 22:36:01.558 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:36:01.608 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:36:01.699 asr_benchmark.c:102:     Loaded WAV: test_039.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:36:01.699 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:36:02.021 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:36:02.021 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:36:10.656 asr_whisper.c:256:       Whisper: Final result: " Friday, what sensors are currently active in the house?" (8635.2ms, RTF: 0.864)[0m
[32m[INFO] 22:36:10.657 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:36:10.678 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:36:10.792 asr_benchmark.c:102:     Loaded WAV: test_040.wav (160000 samples, 16000 Hz, 10.00 seconds)[0m
[32m[INFO] 22:36:10.792 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:36:11.115 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:36:11.115 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:36:19.853 asr_whisper.c:256:       Whisper: Final result: " Friday, give me a summary of today's activities." (8737.8ms, RTF: 0.874)[0m
[32m[INFO] 22:36:19.854 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:36:19.887 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:36:19.971 asr_benchmark.c:102:     Loaded WAV: test_041.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:36:19.972 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:36:20.295 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:36:20.295 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:36:29.412 asr_whisper.c:256:       Whisper: Final result: " Friday, I'm going to do a little bit of testing just to see how my new text-to-speech ASR is working, and we're going to go ahead and run some benchmarks." (9116.6ms, RTF: 0.608)[0m
[32m[INFO] 22:36:29.412 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:36:29.446 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:36:29.525 asr_benchmark.c:102:     Loaded WAV: test_042.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:36:29.525 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:36:29.852 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:36:29.852 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:36:38.956 asr_whisper.c:256:       Whisper: Final result: " Friday, can you tell me about the OASIS project specs, including Mirage, Dawn, Aura, and Spark, and what each component does?" (9103.1ms, RTF: 0.607)[0m
[32m[INFO] 22:36:38.956 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:36:38.990 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:36:39.075 asr_benchmark.c:102:     Loaded WAV: test_043.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:36:39.075 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:36:39.401 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:36:39.401 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:36:48.363 asr_whisper.c:256:       Whisper: Final result: " Friday, I need you to analyze the recent performance metrics and let me know if there are any anomalies or issues that need attention." (8961.1ms, RTF: 0.597)[0m
[32m[INFO] 22:36:48.363 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:36:48.397 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:36:48.486 asr_benchmark.c:102:     Loaded WAV: test_044.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:36:48.486 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:36:48.810 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:36:48.810 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:36:57.677 asr_whisper.c:256:       Whisper: Final result: " Friday, could you please walk me through the steps to configure a new sensor and integrate it with the existing home automation system?" (8865.6ms, RTF: 0.591)[0m
[32m[INFO] 22:36:57.677 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:36:57.710 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:36:57.796 asr_benchmark.c:102:     Loaded WAV: test_045.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:36:57.796 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:36:58.118 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:36:58.118 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:37:07.096 asr_whisper.c:256:       Whisper: Final result: " Friday, I'm experiencing some latency issues with the voice recognition and I'm wondering if it might be related to network bandwidth or processing power." (8977.6ms, RTF: 0.599)[0m
[32m[INFO] 22:37:07.096 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:37:07.130 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:37:07.211 asr_benchmark.c:102:     Loaded WAV: test_046.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:37:07.211 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:37:07.541 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:37:07.541 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:37:16.559 asr_whisper.c:256:       Whisper: Final result: " Friday, give me a detailed breakdown of the energy consumption across all connected devices for the past week and highlight any unusual patterns." (9017.4ms, RTF: 0.601)[0m
[32m[INFO] 22:37:16.559 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:37:16.594 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:37:16.679 asr_benchmark.c:102:     Loaded WAV: test_047.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:37:16.680 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:37:17.002 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:37:17.002 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:37:26.068 asr_whisper.c:256:       Whisper: Final result: " Friday, I want to set up an automation routine that turns on the lights when I arrive home and adjust the thermostat based on the current weather." (9064.6ms, RTF: 0.604)[0m
[32m[INFO] 22:37:26.068 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:37:26.101 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:37:26.190 asr_benchmark.c:102:     Loaded WAV: test_048.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:37:26.190 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:37:26.525 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:37:26.525 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:37:35.645 asr_whisper.c:256:       Whisper: Final result: " Friday, can you compare the performance of VOSC vs. Whisper for speech recognition accuracy, real-time factor, and overall system resource usage?" (9118.7ms, RTF: 0.608)[0m
[32m[INFO] 22:37:35.645 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:37:35.679 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:37:35.768 asr_benchmark.c:102:     Loaded WAV: test_049.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:37:35.768 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:37:36.100 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:37:36.100 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:37:45.154 asr_whisper.c:256:       Whisper: Final result: " Friday, I need to know if the backup systems are functioning properly and when the last successful backup was completed for all critical data." (9053.2ms, RTF: 0.604)[0m
[32m[INFO] 22:37:45.154 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:37:45.190 asr_whisper.c:295:       Whisper: Cleanup complete[0m
[32m[INFO] 22:37:45.281 asr_benchmark.c:102:     Loaded WAV: test_050.wav (240000 samples, 16000 Hz, 15.00 seconds)[0m
[32m[INFO] 22:37:45.282 asr_interface.c:78:      ASR: Initializing Whisper engine (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
whisper_init_from_file_with_params_no_state: loading model from '../whisper.cpp/models/ggml-small.bin'
whisper_init_with_params_no_state: use gpu    = 0
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: Orin, compute capability 8.7, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51865
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 768
whisper_model_load: n_audio_head  = 12
whisper_model_load: n_audio_layer = 12
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 768
whisper_model_load: n_text_head   = 12
whisper_model_load: n_text_layer  = 12
whisper_model_load: n_mels        = 80
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 3 (small)
whisper_model_load: adding 1608 extra tokens
whisper_model_load: n_langs       = 99
whisper_model_load:          CPU total size =   487.01 MB
whisper_model_load: model size    =  487.01 MB
whisper_backend_init_gpu: no GPU found
whisper_init_state: kv self size  =   18.87 MB
whisper_init_state: kv cross size =   56.62 MB
whisper_init_state: kv pad  size  =    4.72 MB
whisper_init_state: compute buffer (conv)   =   22.42 MB
whisper_init_state: compute buffer (encode) =   33.85 MB
whisper_init_state: compute buffer (cross)  =    6.20 MB
whisper_init_state: compute buffer (decode) =   97.28 MB
[32m[INFO] 22:37:45.612 asr_whisper.c:119:       Whisper: Initialized successfully (model: ../whisper.cpp/models/ggml-small.bin, sample_rate: 16000)[0m
[32m[INFO] 22:37:45.612 asr_interface.c:98:      ASR: Whisper engine initialized successfully[0m
[32m[INFO] 22:37:54.481 asr_whisper.c:256:       Whisper: Final result: " Friday, please explain the difference between streaming ASR and batch processing and how that affects the responsiveness of the voice assistant." (8868.7ms, RTF: 0.591)[0m
[32m[INFO] 22:37:54.481 asr_interface.c:148:     ASR: Cleaning up Whisper engine[0m
[32m[INFO] 22:37:54.516 asr_whisper.c:295:       Whisper: Cleanup complete[0m
