# DAWN Configuration File
# ========================
# Copy this file to one of:
#   ./dawn.toml                    (current directory - highest priority)
#   ~/.config/dawn/dawn.toml       (user config)
#   /etc/dawn/dawn.toml            (system-wide)
#
# Or specify explicitly: dawn --config /path/to/config.toml
#
# Values shown are defaults. Uncomment and modify as needed.
# Use --dump-config to see the effective configuration.
# Use --dump-settings to see all settings with their sources and env var names.
#
# Environment variables: Each setting can be overridden via DAWN_<SECTION>_<KEY>
# Example: [audio] capture_device -> DAWN_AUDIO_CAPTURE_DEVICE

# =============================================================================
# General Settings
# =============================================================================

[general]
# ai_name = "friday"              # Wake word / assistant name (lowercase)
                                  # Env: DAWN_GENERAL_AI_NAME
# log_file = ""                   # Log to file (empty = console only)
                                  # Env: DAWN_GENERAL_LOG_FILE

[persona]
# description = ""                # Custom AI personality description
                                  # Leave empty to use built-in persona
                                  # Env: DAWN_PERSONA_DESCRIPTION

[localization]
# location = ""                   # Your location (e.g., "New York, NY")
                                  # Used for weather and contextual responses
                                  # Env: DAWN_LOCALIZATION_LOCATION
# timezone = ""                   # Timezone (e.g., "America/New_York")
                                  # Empty = system default
                                  # Env: DAWN_LOCALIZATION_TIMEZONE
# units = "imperial"              # "imperial" or "metric"
                                  # Env: DAWN_LOCALIZATION_UNITS

# =============================================================================
# Audio Settings
# =============================================================================

[audio]
# backend = "auto"                # "auto", "alsa", or "pulse"
                                  # Env: DAWN_AUDIO_BACKEND
# capture_device = "default"      # Microphone device (use `arecord -L` to list)
                                  # Env: DAWN_AUDIO_CAPTURE_DEVICE
# playback_device = "default"     # Speaker device (use `aplay -L` to list)
                                  # Env: DAWN_AUDIO_PLAYBACK_DEVICE
# output_rate = 44100             # Playback sample rate (44100 or 48000)
                                  # Env: DAWN_AUDIO_OUTPUT_RATE
# output_channels = 2             # Playback channels (2 = stereo, required for dmix)
                                  # Env: DAWN_AUDIO_OUTPUT_CHANNELS

[audio.bargein]
# enabled = true                  # Allow interrupting TTS with speech
                                  # Env: DAWN_AUDIO_BARGEIN_ENABLED
# cooldown_ms = 1500              # Keep high VAD threshold after TTS stops
                                  # Env: DAWN_AUDIO_BARGEIN_COOLDOWN_MS
# startup_cooldown_ms = 300       # Block barge-in when TTS starts
                                  # Env: DAWN_AUDIO_BARGEIN_STARTUP_COOLDOWN_MS

# =============================================================================
# Voice Activity Detection (VAD)
# =============================================================================

[vad]
# speech_threshold = 0.50         # Sensitivity for detecting speech (0.0-1.0)
                                  # Lower = more sensitive
                                  # Env: DAWN_VAD_SPEECH_THRESHOLD
# speech_threshold_tts = 0.92     # Higher threshold during TTS playback
                                  # Prevents echo from triggering VAD
                                  # Env: DAWN_VAD_SPEECH_THRESHOLD_TTS
# silence_threshold = 0.30        # Below this probability = silence
                                  # Env: DAWN_VAD_SILENCE_THRESHOLD
# end_of_speech_duration = 1.2    # Seconds of silence to end recording
                                  # Env: DAWN_VAD_END_OF_SPEECH_DURATION
# max_recording_duration = 30.0   # Maximum recording length in seconds
                                  # Env: DAWN_VAD_MAX_RECORDING_DURATION
# preroll_ms = 500                # Audio to keep before speech detected
                                  # Env: DAWN_VAD_PREROLL_MS

[vad.chunking]
# enabled = true                  # Enable chunked transcription for long utterances
                                  # Env: DAWN_VAD_CHUNKING_ENABLED
# pause_duration = 0.30           # Silence duration (seconds) to trigger chunk boundary
                                  # Env: DAWN_VAD_CHUNKING_PAUSE_DURATION
# min_duration = 1.0              # Minimum chunk duration (seconds)
                                  # Env: DAWN_VAD_CHUNKING_MIN_DURATION
# max_duration = 10.0             # Maximum chunk duration (seconds)
                                  # Env: DAWN_VAD_CHUNKING_MAX_DURATION

# =============================================================================
# Automatic Speech Recognition (ASR)
# =============================================================================

[asr]
# model = "base"                  # Whisper model: "tiny", "base", "small", "medium"
                                  # tiny=fastest, medium=most accurate
                                  # Env: DAWN_ASR_MODEL
# models_path = "models/whisper.cpp"  # Path to Whisper model files
                                  # Env: DAWN_ASR_MODELS_PATH

# =============================================================================
# Text-to-Speech (TTS)
# =============================================================================

[tts]
# models_path = "models"          # Path to TTS model files
                                  # Env: DAWN_TTS_MODELS_PATH
# voice_model = "en_GB-alba-medium"  # Piper voice model name
                                  # Included: en_GB-alba-medium, en_GB-northern_english_male-medium
                                  # Env: DAWN_TTS_VOICE_MODEL
# length_scale = 0.85             # Speech speed: <1.0 = faster, >1.0 = slower
                                  # Env: DAWN_TTS_LENGTH_SCALE

# =============================================================================
# Command Processing
# =============================================================================

[commands]
# processing_mode = "direct_first"  # Command processing strategy:
                                    # "direct_only": Pattern matching only (fastest)
                                    # "llm_only": All commands via LLM (most flexible)
                                    # "direct_first": Try patterns, fall back to LLM
                                    # Env: DAWN_COMMANDS_PROCESSING_MODE

# =============================================================================
# Large Language Model (LLM)
# =============================================================================

[llm]
# type = "cloud"                  # "cloud" or "local"
                                  # Env: DAWN_LLM_TYPE
# max_tokens = 4096               # Maximum response tokens
                                  # Env: DAWN_LLM_MAX_TOKENS
# summarize_threshold = 0.80      # Compact conversation at this % of context limit
                                  # Env: DAWN_LLM_SUMMARIZE_THRESHOLD
# conversation_logging = false    # Save chat history to log files (WebUI saves to DB)
                                  # Env: DAWN_LLM_CONVERSATION_LOGGING

[llm.cloud]
# provider = "openai"             # "openai", "claude", or "gemini"
                                  # Env: DAWN_LLM_CLOUD_PROVIDER
# endpoint = ""                   # Custom endpoint (empty = default provider URL)
                                  # Env: DAWN_LLM_CLOUD_ENDPOINT
# vision_enabled = true           # Cloud models typically support vision/images
                                  # Env: DAWN_LLM_CLOUD_VISION_ENABLED

# Model lists for quick switching via WebUI or voice
# First model in list is used when switching to that provider
# openai_models = ["gpt-5-mini", "gpt-5.2", "gpt-5-nano", "gpt-5"]
# openai_default_model_idx = 0
# claude_models = ["claude-sonnet-4-5", "claude-opus-4-5", "claude-haiku-4-5"]
# claude_default_model_idx = 0
# gemini_models = ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-3-flash-preview", "gemini-3-pro-preview"]
# gemini_default_model_idx = 0

[llm.local]
# endpoint = "http://127.0.0.1:8080"  # Local LLM server endpoint
                                  # llama.cpp default: 8080, Ollama default: 11434
                                  # Env: DAWN_LLM_LOCAL_ENDPOINT
# model = ""                      # Model identifier (optional, server may auto-select)
                                  # Env: DAWN_LLM_LOCAL_MODEL
# vision_enabled = false          # Enable for vision models (LLaVA, Qwen-VL, etc.)
                                  # Env: DAWN_LLM_LOCAL_VISION_ENABLED
# provider = "auto"               # "auto", "ollama", "llama_cpp", or "generic"
                                  # "auto" probes endpoint to detect server type
                                  # Env: DAWN_LLM_LOCAL_PROVIDER

[llm.tools]
# mode = "native"                 # Tool/function calling mode:
                                  # "native": Use provider's native tool calling (recommended)
                                  # "command_tags": Extract JSON from <command> tags (legacy)
                                  # "disabled": No tool calling
                                  # Env: DAWN_LLM_TOOLS_MODE
# local_enabled = []              # Tools enabled for local voice interface (empty = all)
                                  # Example: ["weather", "search", "calculator"]
# remote_enabled = []             # Tools enabled for WebUI/remote clients (empty = all)

[llm.thinking]
# Extended thinking/reasoning mode for complex queries
# mode = "disabled"               # "disabled" or "enabled"
                                  # Env: DAWN_LLM_THINKING_MODE
# reasoning_effort = "medium"     # "low", "medium", "high" - selects which budget to use
                                  # Maps to provider-specific settings:
                                  # - OpenAI o-series/GPT-5: reasoning_effort parameter
                                  # - Claude: budget_tokens
                                  # - Gemini 2.5+: reasoning_effort (cannot fully disable)
                                  # - Local (llama.cpp): budget_tokens
                                  # Env: DAWN_LLM_THINKING_REASONING_EFFORT
# budget_low = 1024               # Token budget for "low" reasoning effort
                                  # Env: DAWN_LLM_THINKING_BUDGET_LOW
# budget_medium = 8192            # Token budget for "medium" reasoning effort
                                  # Env: DAWN_LLM_THINKING_BUDGET_MEDIUM
# budget_high = 16384             # Token budget for "high" reasoning effort
                                  # Env: DAWN_LLM_THINKING_BUDGET_HIGH
                                  # NOTE: Budgets are clamped to 50% of model context size

# =============================================================================
# Web Search (SearXNG)
# =============================================================================

[search]
# engine = "searxng"              # Only "searxng" supported currently
                                  # Env: DAWN_SEARCH_ENGINE
# endpoint = "http://127.0.0.1:8384"  # SearXNG instance URL
                                  # Env: DAWN_SEARCH_ENDPOINT
# title_filters = []              # Exclude results with these terms (case-insensitive)
                                  # Default filters spam like "wordle", "connections hints"

[search.summarizer]
# backend = "disabled"            # Summarize large search results:
                                  # "disabled": Return raw results
                                  # "local": Use dedicated local summarizer (llama-server)
                                  # "default": Use same LLM as conversation
                                  # "tfidf": Fast extractive summarization (no LLM needed)
                                  # Env: DAWN_SEARCH_SUMMARIZER_BACKEND
# threshold_bytes = 3072          # Summarize results larger than this
                                  # Env: DAWN_SEARCH_SUMMARIZER_THRESHOLD_BYTES
# target_words = 600              # Target summary length in words (for LLM backends)
                                  # Env: DAWN_SEARCH_SUMMARIZER_TARGET_WORDS
# target_ratio = 0.2              # Ratio of sentences to keep for TF-IDF (0.2 = 20%)
                                  # Env: DAWN_SEARCH_SUMMARIZER_TARGET_RATIO

# =============================================================================
# URL Fetcher
# =============================================================================

[url_fetcher]
# whitelist = []                  # Domains to always allow fetching (array of strings)
                                  # Example: ["github.com", "docs.python.org"]

[url_fetcher.flaresolverr]
# enabled = false                 # Auto-fallback to FlareSolverr on 403 errors
                                  # Env: DAWN_URL_FETCHER_FLARESOLVERR_ENABLED
# endpoint = "http://127.0.0.1:8191/v1"  # FlareSolverr API endpoint
                                  # Env: DAWN_URL_FETCHER_FLARESOLVERR_ENDPOINT
# timeout_sec = 60                # Request timeout in seconds
                                  # Env: DAWN_URL_FETCHER_FLARESOLVERR_TIMEOUT_SEC
# max_response_bytes = 4194304    # Max response size (4MB)
                                  # Env: DAWN_URL_FETCHER_FLARESOLVERR_MAX_RESPONSE_BYTES

# =============================================================================
# MQTT (Home Automation)
# =============================================================================

[mqtt]
# enabled = true                  # Enable MQTT integration
                                  # Env: DAWN_MQTT_ENABLED
# broker = "127.0.0.1"            # MQTT broker hostname/IP
                                  # Env: DAWN_MQTT_BROKER
# port = 1883                     # MQTT broker port
                                  # Env: DAWN_MQTT_PORT
# Note: Credentials go in secrets.toml under [mqtt]
#       or use env vars: MQTT_USERNAME, MQTT_PASSWORD

# =============================================================================
# Network (shared settings for sessions, workers, LLM timeouts)
# =============================================================================

[network]
# workers = 4                     # Concurrent processing threads
                                  # Env: DAWN_NETWORK_WORKERS
# session_timeout_sec = 1800      # Idle session expiry (30 minutes)
                                  # Env: DAWN_NETWORK_SESSION_TIMEOUT_SEC
# llm_timeout_ms = 60000          # Per-request LLM timeout (60 seconds)
                                  # Env: DAWN_NETWORK_LLM_TIMEOUT_MS

# =============================================================================
# Web UI
# =============================================================================

[webui]
# enabled = false                 # Enable Web UI server (set true to use browser interface)
                                  # Env: DAWN_WEBUI_ENABLED
# port = 3000                     # HTTP/WebSocket port
                                  # Env: DAWN_WEBUI_PORT
# bind_address = "0.0.0.0"        # Bind address (0.0.0.0 = all interfaces)
                                  # Env: DAWN_WEBUI_BIND_ADDRESS
# max_clients = 4                 # Max concurrent WebSocket clients
                                  # Env: DAWN_WEBUI_MAX_CLIENTS
# audio_chunk_ms = 200            # Audio chunk size for streaming (100-500ms)
                                  # Env: DAWN_WEBUI_AUDIO_CHUNK_MS
# workers = 1                     # ASR worker threads for voice input
                                  # Env: DAWN_WEBUI_WORKERS
# www_path = "www"                # Path to static web files
                                  # Env: DAWN_WEBUI_WWW_PATH

# SSL/HTTPS (required for microphone access from non-localhost)
# https = false                   # Enable HTTPS
                                  # Env: DAWN_WEBUI_HTTPS
# ssl_cert_path = ""              # Path to SSL certificate (.pem or .crt)
                                  # Env: DAWN_WEBUI_SSL_CERT_PATH
# ssl_key_path = ""               # Path to SSL private key (.pem or .key)
                                  # Env: DAWN_WEBUI_SSL_KEY_PATH

# =============================================================================
# Image Storage (vision uploads)
# =============================================================================

[images]
# retention_days = 0              # Delete images older than N days (0 = never delete)
# max_size_mb = 4                 # Maximum size per uploaded image in MB
# max_per_user = 1000             # Maximum stored images per user

# =============================================================================
# Persistent Memory System
# =============================================================================

[memory]
# enabled = true                  # Enable persistent user memory
# context_budget_tokens = 800     # Max tokens for memory context in system prompt
# extraction_provider = "local"   # LLM provider for fact extraction: "local", "openai", "claude"
# extraction_model = "qwen2.5:7b" # Model for memory extraction
# pruning_enabled = true          # Automatically remove old superseded and stale facts
# prune_superseded_days = 30      # Keep superseded facts for N days before deletion
# prune_stale_days = 180          # Delete low-confidence facts not accessed in N days
# prune_stale_min_confidence = 0.50  # Only prune stale facts with confidence below this
# conversation_idle_timeout_min = 15  # Auto-save voice conversations after N minutes idle
                                  # (0 = disabled, minimum 10 if enabled)
# default_voice_user_id = 1       # User account for local microphone and DAP conversations

[memory.decay]
# enabled = true                  # Enable nightly confidence decay
# hour = 2                        # Hour to run decay (0-23, local time)
# inferred_weekly = 0.95          # Weekly decay multiplier for inferred facts (5%/week)
# explicit_weekly = 0.98          # Weekly decay multiplier for explicit facts (2%/week)
# preference_weekly = 0.97        # Weekly decay multiplier for preferences (3%/week)
# inferred_floor = 0.0            # Min confidence for inferred facts (0 = can decay to zero)
# explicit_floor = 0.50           # Min confidence for explicit facts (never fully forgotten)
# preference_floor = 0.40         # Min confidence for preferences
# prune_threshold = 0.25          # Delete facts with confidence below this after decay
# summary_retention_days = 30     # Delete conversation summaries older than N days
# access_reinforcement_boost = 0.05  # Confidence boost when a fact is accessed (+5%)
                                  # Time-gated: only boosts once per hour to prevent pinning

# =============================================================================
# Scheduler (timers, alarms, reminders)
# =============================================================================

[scheduler]
# enabled = true                  # Enable scheduler system
# default_snooze_minutes = 10     # Default snooze duration
# max_snooze_count = 10           # Maximum snooze attempts per event
# max_events_per_user = 50        # Maximum active events per user
# max_events_total = 200          # Maximum active events system-wide
# missed_event_recovery = true    # Fire missed events on startup
# missed_task_policy = "skip"     # Missed scheduled tasks: "skip" or "execute"
# missed_task_max_age_sec = 300   # Max age for executing missed tasks (5 minutes)
# alarm_timeout_sec = 60          # Auto-dismiss alarms after N seconds
# alarm_volume = 80               # Alarm chime volume (0-100)
# event_retention_days = 30       # Keep completed events for N days

# =============================================================================
# Music Playback
# =============================================================================

[music]
# scan_interval_minutes = 60      # Rescan music library for new files (minutes)
# streaming_enabled = true        # Enable Opus streaming to WebUI and satellites
# streaming_quality = "standard"  # Opus encoding quality
# streaming_bitrate_mode = "vbr"  # Bitrate mode: "vbr" or "cbr"

# =============================================================================
# Shutdown Control
# =============================================================================

[shutdown]
# enabled = false                 # Enable voice/command shutdown (security risk)
                                  # Env: DAWN_SHUTDOWN_ENABLED
# passphrase = ""                 # Required passphrase (empty = no passphrase)
                                  # Env: DAWN_SHUTDOWN_PASSPHRASE

# =============================================================================
# Terminal UI (TUI)
# =============================================================================

[tui]
# enabled = false                 # Enable ncurses TUI dashboard
                                  # Env: DAWN_TUI_ENABLED

# =============================================================================
# Debug Settings
# =============================================================================

[debug]
# mic_record = false              # Record raw microphone input
                                  # Env: DAWN_DEBUG_MIC_RECORD
# asr_record = false              # Record audio sent to ASR
                                  # Env: DAWN_DEBUG_ASR_RECORD
# aec_record = false              # Record AEC processed audio
                                  # Env: DAWN_DEBUG_AEC_RECORD
# record_path = "/tmp"            # Directory for debug recordings
                                  # Env: DAWN_DEBUG_RECORD_PATH

# =============================================================================
# File Paths
# =============================================================================

[paths]
# data_dir = "~/.local/share/dawn"  # Database storage directory
                                  # Env: DAWN_PATHS_DATA_DIR
# music_dir = "~/Music"           # Music library location for playback
                                  # Env: DAWN_PATHS_MUSIC_DIR
# commands_config = "commands_config_nuevo.json"  # Device/command mappings for MQTT
                                  # Env: DAWN_PATHS_COMMANDS_CONFIG

# =============================================================================
# Secrets (separate file)
# =============================================================================
# API keys and credentials should go in secrets.toml (mode 600 recommended)
# See secrets.toml.example for format
#
# Environment variable alternatives:
#   OPENAI_API_KEY, CLAUDE_API_KEY, GEMINI_API_KEY (for LLM)
#   MQTT_USERNAME, MQTT_PASSWORD (for MQTT auth)
